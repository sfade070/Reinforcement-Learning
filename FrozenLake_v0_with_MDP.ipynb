{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FrozenLake-v0 with MDP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvmZVwncUKLv",
        "colab_type": "text"
      },
      "source": [
        "# Importing dependency libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTpRxgEt1o4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import gym\n",
        "import numpy as np\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHdeL_i4UO1n",
        "colab_type": "text"
      },
      "source": [
        "# Load the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGKfaVSaUS92",
        "colab_type": "code",
        "outputId": "b35cf8d2-9510-4c94-dae0-4f072290ee51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "env = gym.make('FrozenLake-v0')\n",
        "\n",
        "s = env.reset()\n",
        "print(s)\n",
        "print()\n",
        "\n",
        "env.render()\n",
        "print()\n",
        "\n",
        "print(env.action_space) #number of actions\n",
        "print(env.observation_space) #number of states\n",
        "print()\n",
        "\n",
        "print(\"Number of actions : \",env.action_space.n)\n",
        "print(\"Number of states : \",env.observation_space.n)\n",
        "print()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "\n",
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "\n",
            "Discrete(4)\n",
            "Discrete(16)\n",
            "\n",
            "Number of actions :  4\n",
            "Number of states :  16\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peA4TLIyUWgw",
        "colab_type": "text"
      },
      "source": [
        "# Value Iteration Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IJpFtMtUe-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initializing Utilities of all states with zeros\n",
        "U = np.zeros([env.observation_space.n])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coK8YYsbVXlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#since terminal states have utility values equal to their reward\n",
        "U[15] = 1 #goal state\n",
        "U[[5,7,11,12]] = -1 #hole states\n",
        "termS = [5,7,11,12,15] #terminal states"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7g5xHLqVcIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#set hyperparameters\n",
        "y = 0.8 #discount factor lambda\n",
        "eps = 1e-3 #threshold if the learning difference i.e. prev_u - U goes below this value break the learning "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxq_vg8wViNR",
        "colab_type": "code",
        "outputId": "7b3994f0-f078-482f-f43a-45b8491c6417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "i=0\n",
        "while(True):\n",
        "\ti+=1\n",
        "\tprev_u = np.copy(U)\n",
        "\tfor s in range(env.observation_space.n):\n",
        "\t\tq_sa = [sum([p*(r + y*prev_u[s_]) for p, s_, r, _ in env.env.P[s][a]]) for a in range(env.action_space.n)]\n",
        "\t\tif s not in termS: \n",
        "\t\t\tU[s] = max(q_sa)\n",
        "\tif (np.sum(np.fabs(prev_u - U)) <= eps):\n",
        "\t\tprint ('Value-iteration converged at iteration# %d.' %(i+1))\n",
        "\t\tbreak"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Value-iteration converged at iteration# 25.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnUm5ew6Vqkh",
        "colab_type": "code",
        "outputId": "496b88cd-07ce-4cc0-d43a-ecbeb45b65e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(\"After learning completion printing the utilities for each states below from state ids 0-15\")\n",
        "print()\n",
        "print(U[:4])\n",
        "print(U[4:8])\n",
        "print(U[8:12])\n",
        "print(U[12:16])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After learning completion printing the utilities for each states below from state ids 0-15\n",
            "\n",
            "[0.023482   0.00999637 0.00437564 0.0023448 ]\n",
            "[ 0.0415207  -1.         -0.19524141 -1.        ]\n",
            "[ 0.09109598  0.20932556  0.26362693 -1.        ]\n",
            "[-1.          0.43048408  0.97468581  1.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}